#!/usr/bin/env php
<?php

// Check if running from command line
if (php_sapi_name() !== 'cli') {
    die('This script can only be run from the command line.' . PHP_EOL);
}

// Autoload
$autoloadPaths = [
    __DIR__ . '/../vendor/autoload.php',
    __DIR__ . '/../../../autoload.php',
];

$autoloaded = false;
foreach ($autoloadPaths as $autoloadPath) {
    if (file_exists($autoloadPath)) {
        require $autoloadPath;
        $autoloaded = true;
        break;
    }
}

if (!$autoloaded) {
    die('Error: Composer autoload not found. Run "composer install" first.' . PHP_EOL);
}

use IProDev\Sitemap\Fetcher;
use IProDev\Sitemap\Crawler;
use IProDev\Sitemap\SitemapWriter;
use IProDev\Sitemap\RobotsTxt;
use IProDev\Sitemap\Utils;

/**
 * Simple console logger
 */
class ConsoleLogger extends \Psr\Log\AbstractLogger {
    private bool $verbose;
    private float $startTime;

    public function __construct(bool $verbose = false) {
        $this->verbose = $verbose;
        $this->startTime = microtime(true);
    }

    public function log($level, $message, array $context = []): void {
        $timestamp = sprintf('[%.2fs]', microtime(true) - $this->startTime);
        
        // Only show info and above unless verbose
        if (!$this->verbose && in_array($level, ['debug'])) {
            return;
        }

        $levelColors = [
            'emergency' => "\033[1;31m", // Bold Red
            'alert'     => "\033[1;31m", // Bold Red
            'critical'  => "\033[1;31m", // Bold Red
            'error'     => "\033[0;31m", // Red
            'warning'   => "\033[0;33m", // Yellow
            'notice'    => "\033[0;36m", // Cyan
            'info'      => "\033[0;32m", // Green
            'debug'     => "\033[0;37m", // White
        ];

        $reset = "\033[0m";
        $color = $levelColors[$level] ?? '';

        $contextStr = !empty($context) ? ' ' . json_encode($context) : '';
        echo "{$timestamp} {$color}[{$level}]{$reset} {$message}{$contextStr}" . PHP_EOL;
    }
}

/**
 * Display help message
 */
function showHelp(): void {
    echo <<<HELP
PHP XML Sitemap Generator - Professional CLI Tool

Usage:
  sitemap --url=<URL> [OPTIONS]

Required Options:
  --url=<URL>              Starting URL to crawl (must be valid http/https URL)

Optional Options:
  --out=<PATH>             Output directory (default: ./output)
  --concurrency=<N>        Number of concurrent HTTP requests (default: 10, max: 100)
  --max-pages=<N>          Maximum pages to crawl (default: 50000)
  --max-depth=<N>          Maximum link depth to follow (default: 5)
  --public-base=<URL>      Public base URL for sitemap file URLs in index
  --verbose, -v            Enable verbose output
  --help, -h               Show this help message

Examples:
  # Basic usage
  sitemap --url=https://www.example.com

  # With custom settings
  sitemap --url=https://www.example.com --out=./sitemaps --concurrency=20 --max-pages=10000

  # With public base URL for sitemap index
  sitemap --url=https://www.example.com --public-base=https://cdn.example.com/sitemaps

  # Verbose mode
  sitemap --url=https://www.example.com --verbose

HELP;
}

/**
 * Parse command line arguments
 */
function parseArguments(): array {
    $options = getopt('hv', [
        'url:',
        'out::',
        'concurrency::',
        'max-pages::',
        'max-depth::',
        'public-base::',
        'verbose',
        'help'
    ]);

    // Show help
    if (isset($options['h']) || isset($options['help'])) {
        showHelp();
        exit(0);
    }

    // Required: URL
    if (!isset($options['url']) || empty($options['url'])) {
        echo "Error: --url is required\n\n";
        showHelp();
        exit(1);
    }

    // Validate URL
    if (!Utils::isValidUrl($options['url'])) {
        echo "Error: Invalid URL format: {$options['url']}\n";
        exit(1);
    }

    // Parse options with defaults
    $config = [
        'url'         => $options['url'],
        'out'         => $options['out'] ?? './output',
        'concurrency' => (int)($options['concurrency'] ?? 10),
        'maxPages'    => (int)($options['max-pages'] ?? 50000),
        'maxDepth'    => (int)($options['max-depth'] ?? 5),
        'publicBase'  => $options['public-base'] ?? null,
        'verbose'     => isset($options['v']) || isset($options['verbose'])
    ];

    // Validate numeric options
    if ($config['concurrency'] < 1 || $config['concurrency'] > 100) {
        echo "Error: concurrency must be between 1 and 100\n";
        exit(1);
    }

    if ($config['maxPages'] < 1) {
        echo "Error: max-pages must be at least 1\n";
        exit(1);
    }

    if ($config['maxDepth'] < 0) {
        echo "Error: max-depth must be non-negative\n";
        exit(1);
    }

    return $config;
}

/**
 * Display configuration summary
 */
function showConfig(array $config): void {
    echo "\n" . str_repeat('=', 70) . "\n";
    echo "  PHP XML Sitemap Generator\n";
    echo str_repeat('=', 70) . "\n";
    echo "Configuration:\n";
    echo "  URL:         {$config['url']}\n";
    echo "  Domain:      " . Utils::getDomain($config['url']) . "\n";
    echo "  Output:      {$config['out']}\n";
    echo "  Concurrency: {$config['concurrency']}\n";
    echo "  Max Pages:   {$config['maxPages']}\n";
    echo "  Max Depth:   {$config['maxDepth']}\n";
    if ($config['publicBase']) {
        echo "  Public Base: {$config['publicBase']}\n";
    }
    echo str_repeat('=', 70) . "\n\n";
}

// Main execution
try {
    // Parse arguments
    $config = parseArguments();
    
    // Create logger
    $logger = new ConsoleLogger($config['verbose']);
    
    // Show configuration
    showConfig($config);
    
    $startTime = microtime(true);
    
    // Initialize components
    $logger->info("Initializing crawler...");
    $fetcher = new Fetcher([
        'concurrency' => $config['concurrency'],
        'timeout' => 15
    ], $logger);
    
    // Load robots.txt
    $logger->info("Fetching robots.txt...");
    $robots = RobotsTxt::fromUrl($config['url'], $fetcher);
    $logger->info("Robots.txt loaded", [
        'disallows' => count($robots->getDisallows()),
        'allows' => count($robots->getAllows())
    ]);
    
    // Create crawler
    $crawler = new Crawler($fetcher, $robots, $logger);
    
    // Start crawling
    $logger->info("Starting crawl...");
    $pages = $crawler->crawl($config['url'], $config['maxPages'], $config['maxDepth']);
    
    $crawlTime = microtime(true) - $startTime;
    $logger->info("Crawl completed", [
        'duration' => Utils::formatDuration($crawlTime),
        'pages' => count($pages),
        'rate' => round(count($pages) / $crawlTime, 2) . ' pages/sec'
    ]);
    
    // Write sitemap files
    $logger->info("Writing sitemap files...");
    $files = SitemapWriter::write($pages, $config['out'], 50000, $config['publicBase']);
    
    $totalTime = microtime(true) - $startTime;
    
    // Success summary
    echo "\n" . str_repeat('=', 70) . "\n";
    echo "  ✅ Success!\n";
    echo str_repeat('=', 70) . "\n";
    echo "Generated Files:\n";
    foreach ($files as $file) {
        $size = file_exists($file) ? Utils::formatBytes(filesize($file)) : 'N/A';
        $basename = basename($file);
        echo "  • {$basename} ({$size})\n";
    }
    echo "\nStatistics:\n";
    echo "  • Total Pages:    " . count($pages) . "\n";
    echo "  • Total Time:     " . Utils::formatDuration($totalTime) . "\n";
    echo "  • Crawl Speed:    " . round(count($pages) / $crawlTime, 2) . " pages/sec\n";
    echo "  • Memory Used:    " . Utils::getPeakMemoryUsage() . "\n";
    echo "  • Output Dir:     {$config['out']}\n";
    echo str_repeat('=', 70) . "\n";
    
    exit(0);
    
} catch (\InvalidArgumentException $e) {
    echo "\n❌ Configuration Error: {$e->getMessage()}\n\n";
    exit(1);
} catch (\RuntimeException $e) {
    echo "\n❌ Runtime Error: {$e->getMessage()}\n\n";
    exit(1);
} catch (\Throwable $e) {
    echo "\n❌ Unexpected Error: {$e->getMessage()}\n";
    if (isset($logger) && $config['verbose']) {
        echo "\nStack Trace:\n" . $e->getTraceAsString() . "\n";
    }
    echo "\n";
    exit(1);
}
